{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpO5NE34z3Ty"
   },
   "source": [
    "Data from: http://zhao-nas.bio.cmu.edu:5000/fsdownload/aBDx29J7H/Ensemble%20learning%20data_shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N_GBOIxuOFq8",
    "outputId": "54418c39-8744-4654-8965-c7a0b986dd52"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m3m-m\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install wandb\n",
    "# !pip install pytorch_lightning\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "783KVUhBVn9-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\anaconda3\\envs\\ensemble_vision\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import cv2 , os, numpy as np, torch, pandas as pd, tqdm as tqdm, PIL.Image as Image, time, IPython\n",
    "#from pylab import rcParams\n",
    "import datetime\n",
    "# \n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from pytorch_lightning.loops.fit_loop import FitLoop\n",
    "from pytorch_lightning.loops.loop import Loop\n",
    "#\n",
    "from numpy.lib.function_base import select\n",
    "from sklearn.preprocessing import LabelBinarizer, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "#import efficientnet_pytorch\n",
    "import pytorch_lightning as pl, torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "F3Rn6pJjXGPh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__module__': '__main__', 'proj_path': WindowsPath('C:/data/MattM_Ensemble'), 'model_path': WindowsPath('C:/data/MattM_Ensemble/model_chkpts'), 'data_path': WindowsPath('C:/data'), 'dataindex_fn': 'dataIndex.csv', 'dataindex_path': WindowsPath('C:/data/dataIndex.csv'), 'data_name': ['HE_RBG_Corp_images'], 'class_names': ['Responder', 'NonResponder'], '__dict__': <attribute '__dict__' of 'PATH_ARGS' objects>, '__weakref__': <attribute '__weakref__' of 'PATH_ARGS' objects>, '__doc__': None}\n"
     ]
    }
   ],
   "source": [
    "class PATH_ARGS:\n",
    "    proj_path = Path('./').absolute()  # [CHANGE THIS for new environment]\n",
    "    model_path = proj_path/'model_chkpts'\n",
    "    # data path\n",
    "    #data_path = proj_path/'TestingData'   # Test path\n",
    "    #data_path = proj_path/'Ensemble_learning data'      # [CONFIRM THIS for new environment]\n",
    "    data_path = proj_path.parent\n",
    "    dataindex_fn = 'dataIndex.csv'\n",
    "    dataindex_path = data_path/dataindex_fn\n",
    "    # 2 types of images (HE  FISH)\n",
    "    data_name = ['HE_RBG_Corp_images']\n",
    "    #data_name = ['HE images', 'HIPT_AGH_FluorescentImage_R1']\n",
    "    # 2 groups to classify\n",
    "    class_names = ['Responder','NonResponder']\n",
    "    \n",
    "print(PATH_ARGS.__dict__)\n",
    "def mkdirifNE(p):\n",
    "    if not os.path.exists(p): os.mkdir(p)\n",
    "\n",
    "mkdirifNE(PATH_ARGS.model_path)\n",
    "\n",
    "def load_img(img_paths: list, is_mask=False):\n",
    "        \"\"\" load array from a list of image paths \"\"\"\n",
    "        if is_mask: flag = 0\n",
    "        else: flag = -1\n",
    "        return np.concatenate([np.expand_dims(cv2.imread(str(img_fp), flag), axis=0)\n",
    "                               for img_fp in img_paths.tolist()])\n",
    "def normalize(ratios):\n",
    "    \"\"\"normalize a list of ratios to sum to 1\"\"\"\n",
    "    return [r/sum(ratios) for r in ratios]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IC1aUI5cbwld"
   },
   "outputs": [],
   "source": [
    "data_index_df = pd.read_csv(PATH_ARGS.data_path/'dataIndex.csv', index_col=0, on_bad_lines='skip')\n",
    "# print(data_index_df['set'].unique())\n",
    "# print(data_index_df['set'].value_counts())\n",
    "data_index_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjnyh2KKfp3L"
   },
   "source": [
    "### Dataloader - loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVqkEUQlftyf"
   },
   "outputs": [],
   "source": [
    "class META_ARGS:\n",
    "    rcParams['figure.figsize'] = 12, 8\n",
    "    RANDOM_SEED = 42\n",
    "    INPUT_DIM = (224,224)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class DATA_ARGS:\n",
    "    num_classes = 2\n",
    "    batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rvj6sDvItzfJ"
   },
   "outputs": [],
   "source": [
    "def _get_normalize_attributes(data_index_df):\n",
    "    x_imgs = load_img(data_index_df['x_img_path'])\n",
    "    means, stds = np.mean(x_imgs, axis=((0,1,2))), np.std(x_imgs, axis=((0,1,2)))\n",
    "    return means, stds\n",
    "\n",
    "# dataloader\n",
    "class HEData(Dataset):\n",
    "    def __init__(self, dataindex_df:Path,\n",
    "                 x_img_cols:str=['x_img_path'], y_cols:list=['label'],\n",
    "                 transform=None, target_transform=None,\n",
    "                 debug:bool=False):\n",
    "        \"\"\" \n",
    "        parameters\n",
    "            csv_file: contain indexer file\n",
    "            \n",
    "        \"\"\"\n",
    "        self.debug = debug\n",
    "        # \n",
    "        self.n = len(dataindex_df)\n",
    "        self.num_classes = dataindex_df['label'].nunique()\n",
    "        # fetch individual \n",
    "        self.x_img_ds = dataindex_df[x_img_cols]\n",
    "        self.y_ds = dataindex_df[y_cols]\n",
    "        self.y_ds_enc = self.label_encode(self.y_ds)  \n",
    "        print(f\"Target shape:{self.y_ds_enc.shape}\")\n",
    "        #\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        print(f\"[INFO]Image classes: {self.num_classes} with {self.n} instances.\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def label_encode(self, ys, oh:bool=False):\n",
    "        # encode target label\n",
    "        if oh:\n",
    "            self.enc = OneHotEncoder()\n",
    "            return self.enc.fit_transform(ys).toarray()\n",
    "        else:\n",
    "            self.enc = LabelBinarizer()\n",
    "        ys_enc = self.enc.fit_transform(ys)\n",
    "        return ys_enc.flatten()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # input images\n",
    "        indexes = list(range(idx))\n",
    "            # get data\n",
    "        x_data = Image.open(self.x_img_ds.iloc[idx][0])\n",
    "        if self.debug: print(f'indexes: {self.x_img_ds.iloc[idx].name}')\n",
    "        y_data = self.y_ds_enc[idx]    #.reshape((-1,))\n",
    "        if self.transform:\n",
    "            x_data = self.transform(x_data)\n",
    "        \n",
    "        if self.target_transform:\n",
    "            y_data = self.target_transform(y_data)\n",
    "        # outputs g(t)\n",
    "        if self.debug: print(x_data.shape, x_data.dtype, y_data.shape, y_data.dtype)\n",
    "        return x_data, y_data\n",
    "\n",
    "def get_transforms(target_size=(224,224), get_normalizing_attributes:bool=False, data_index_df:pd.DataFrame=False):    \n",
    "    assert bool(get_normalizing_attributes) == bool(data_index_df), \"must be provided together\"\n",
    "    if get_normalizing_attributes:\n",
    "        im_means, im_stds = _get_normalize_attributes()\n",
    "    else:   # use pre-computed values\n",
    "        im_means, im_stds=[0, 0, 0], [1, 1, 1]\n",
    "    ## Transforms\n",
    "    process_transform = T.Compose([\n",
    "        T.ToTensor(),\n",
    "    ]) # Normalize by channel means, stds\n",
    "    color_transform = T.Compose([\n",
    "        # In-place transformations\n",
    "        A.RandomBrightnessContrast(p=p2),\n",
    "        A.RandomGamma(gamma_limit=(80, 200), p=p3),\n",
    "        A.Blur(blur_limit=7, p=p2),\n",
    "        A.ToGray(p=p2),\n",
    "        A.CLAHE(p=p2),\n",
    "        A.ChannelDropout(channel_drop_range=(1, 2), fill_value=0, p=p2),\n",
    "        A.ChannelShuffle(p=p2),\n",
    "        A.ColorJitter(\n",
    "            brightness=0.2,\n",
    "            contrast=0.2,\n",
    "            saturation=0.2,\n",
    "            hue=0.2,\n",
    "            always_apply=False,\n",
    "            p=p2,\n",
    "        ),\n",
    "        A.Equalize(mode=\"cv\", by_channels=True, mask=None, mask_params=(), p=p2),\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0), mean=0, per_channel=True, p=p2),\n",
    "        A.Posterize(num_bits=4, p=p2),\n",
    "        A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=p2),\n",
    "        T.GaussianBlur(11, sigma=(0.1, 2.0)),\n",
    "    ])\n",
    "    geometric_transform = T.Compose([\n",
    "        A.Affine(\n",
    "            scale=(0.60, 1.60),\n",
    "            interpolation=cv2.INTER_LINEAR,\n",
    "            cval=0,\n",
    "            cval_mask=0,\n",
    "            mode=cv2.BORDER_CONSTANT,\n",
    "            fit_output=False,\n",
    "            p=p1,\n",
    "        ),\n",
    "        A.Affine(\n",
    "            translate_percent=(-0.2, 0.2),\n",
    "            interpolation=cv2.INTER_LINEAR,\n",
    "            cval=0,\n",
    "            cval_mask=0,\n",
    "            mode=cv2.BORDER_CONSTANT,\n",
    "            fit_output=False,\n",
    "            p=p1,\n",
    "        ),\n",
    "        A.Affine(\n",
    "            rotate=(-30, 30),\n",
    "            interpolation=cv2.INTER_LINEAR,\n",
    "            cval=0,\n",
    "            cval_mask=0,\n",
    "            mode=cv2.BORDER_CONSTANT,\n",
    "            fit_output=False,\n",
    "            p=p1,\n",
    "        ),\n",
    "        A.Affine(\n",
    "            shear=(-20, 20),\n",
    "            interpolation=cv2.INTER_LINEAR,\n",
    "            cval=0,\n",
    "            cval_mask=0,\n",
    "            mode=cv2.BORDER_CONSTANT,\n",
    "            fit_output=False,\n",
    "            p=p1,\n",
    "        ),\n",
    "        # A.OpticalDistortion(distort_limit=2, shift_limit=0.5, p=pt),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "    ])\n",
    "    ###\n",
    "    transformers = {'process': process_transform,  \n",
    "                    'color': color_transform, 'geometric': geometric_transform}\n",
    "    set_transformers = {'train': T.Compose(color_transform.transforms + geometric_transform.transforms + process_transform.transforms),\n",
    "                        'val': T.Compose(process_transform.transforms),\n",
    "                        'test': T.Compose(process_transform.transforms)}\n",
    "    return set_transformers\n",
    "    #return transformers\n",
    "\n",
    "\n",
    "# Get dataset objects\n",
    "class HEdataset:\n",
    "    def __init__(self, dataindex_path:Path, debug:bool=False, **kwargs):\n",
    "        \"\"\" fetch train,val, test datasets with appropriate transform\"\"\"\n",
    "        # read in dataframe\n",
    "        self.dataindex_df = pd.read_csv(dataindex_path, index_col=0)\n",
    "        self.transforms = get_transforms()\n",
    "        self.debug = debug\n",
    "\n",
    "    @property\n",
    "    def datasets(self):\n",
    "        datasets = dict()\n",
    "        # ['train', 'test', 'val']\n",
    "        dataindex_df = self.dataindex_df[self.dataindex_df['set'].isnull()!=True]\n",
    "        for dset in dataindex_df['set'].unique():\n",
    "            print(type(dset), dset)\n",
    "            datasets[dset] = HEData(dataindex_df[dataindex_df['set']==dset],\n",
    "                                    transform = self.transforms[dset], debug=self.debug)\n",
    "        return datasets\n",
    "\n",
    "    @property\n",
    "    def whole(self):\n",
    "        ## Get full dataset\n",
    "        return HEData(self.dataindex_df)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_iadyH-ar2kB"
   },
   "outputs": [],
   "source": [
    "# full dataset objecct\n",
    "class HEDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=64, dataindex_path=Path('./')):\n",
    "        super().__init__()\n",
    "        self.dataindex_path = dataindex_path\n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = DATA_ARGS.num_classes\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        HEdatasets = HEdataset(PATH_ARGS.data_path/'dataIndex.csv').datasets\n",
    "        #\n",
    "        self.train_dataset = HEdatasets['train']\n",
    "        self.validation_dataset = HEdatasets['val']\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_loader = DataLoader(\n",
    "          self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        valid_loader = DataLoader(\n",
    "          self.validation_dataset, batch_size=self.batch_size, shuffle=False)       \n",
    "        return valid_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-2zwr80fr_0"
   },
   "source": [
    "### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZjWd492DsUb"
   },
   "outputs": [],
   "source": [
    "# model and train args\n",
    "class MODEL_ARGS:\n",
    "    n_classes = len(PATH_ARGS.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcE8La0ftMU4"
   },
   "outputs": [],
   "source": [
    "# returns the size of the output tensor going into Linear layer from the conv block.\n",
    "def _get_conv_output(self, shape):\n",
    "    batch_size = 1\n",
    "    input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
    "\n",
    "    output_feat = self._forward_features(input) \n",
    "    n_size = output_feat.data.view(batch_size, -1).size(1)\n",
    "    return n_size\n",
    "    \n",
    "#from torch._C import device\n",
    "class HEClassificationModel(pl.LightningModule):\n",
    "    def __init__(self, model_name:str, n_classes:int=2, pretrain:bool=True,\n",
    "                 custom_classification_head:bool=False, debug:bool=False):\n",
    "        super().__init__()\n",
    "        print(f\"Using pre-trained head:{model_name}\")\n",
    "        avail_models =  ['mobilenetv3','resnext101','efficientnetb7','resnet50']\n",
    "        assert model_name in ['mobilenetv3','resnext101','efficientnetb7','resnet50'], f\"Must be one of {avail_models}\"\n",
    "        self.debug = debug\n",
    "        self.n_classes = n_classes\n",
    "        self.custom_classification_head = custom_classification_head\n",
    "        # Step 1: Initialize model with the weights\n",
    "        if model_name == 'mobilenetv3':\n",
    "            self.model = models.mobilenet_v3_large(pretrained=pretrain)\n",
    "        elif model_name == 'resnext101':\n",
    "            self.model = models.resnext101_32x8d(pretrained=pretrain)    \n",
    "        elif model_name == 'efficientnetb7':\n",
    "            self.model = models.efficientnet_b7(pretrained=pretrain)\n",
    "        elif model_name =='resnet50':\n",
    "            self.model = models.resnet50(pretrained=pretrain)\n",
    "        # replace/remove head\n",
    "        removed = list(self.model.children())[:-1]\n",
    "        self.model_base = torch.nn.Sequential(*removed)  \n",
    "            # head\n",
    "        if self.custom_classification_head:\n",
    "            self.model_head = self.classification_head()\n",
    "        else:\n",
    "            self.model_head = nn.Sequential(nn.Flatten(),\n",
    "                                            nn.Linear(in_features=self.model.classifier[-1].in_features, out_features=self.n_classes, bias=True),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.LogSoftmax(dim=1) if n_classes>2 else nn.Sigmoid(),\n",
    "                                           )\n",
    "        self.model = torch.nn.Sequential(self.model_base, self.model_head)\n",
    "            #self.model_head.to(device=META_ARGS.device)     \n",
    "        # metrics\n",
    "        self.accuracy = torchmetrics.Accuracy()\n",
    "        #self.ROC = torchmetrics.ROC(num_classes=n_classes)\n",
    "        self.AUROC = torchmetrics.AUROC(num_classes=n_classes, pos_label=1)\n",
    "        \n",
    "\n",
    "    def _forward_feature_extract(self, x):\n",
    "        return self.model_base(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_feature_extract(x)\n",
    "        \n",
    "        #x = self.model_head(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(nn.Linear(in_features=self.model.classifier[-1].in_features, out_features=self.n_classes, bias=True)(x))\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        #self.model.classifier = nn.Sequential(*self.model.classifier, nn.Softmax())\n",
    "        if self.debug: print(f\"Num classes:{self.n_classes}\\nModel classifier\\n:{self.model_head}\")\n",
    "        return x\n",
    "\n",
    "    def add_classification_head(self):\n",
    "        #n_features = self.model_head.fc.in_features\n",
    "        classifier_layer = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.model_base.classifier[1].in_features, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512 , 256),\n",
    "            nn.Linear(256 , self.n_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "            )\n",
    "        return classifier_layer\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=1e-10)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def get_loss(self, y_hat, y):\n",
    "        #loss = nn.CrossEntropyLoss()   # does softmax for you (no need in classifcation)\n",
    "        #loss = nn.LogSoftmax()\n",
    "        #loss = F.nll_loss\n",
    "        if self.debug: print(y.size(), y.dtype, y_hat.size(), y_hat.dtype)\n",
    "        return F.cross_entropy(y_hat,  y)\n",
    "\n",
    "    def training_step(self, batch, batch_idx=None):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.get_loss(y_hat, y)\n",
    "        # training metrics\n",
    "        acc = self.accuracy(torch.argmax(y_hat, dim=1), y)\n",
    "        # optimize (done under the hoood)\n",
    "\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, logger=True)\n",
    "        return loss\n",
    "        #return self.get_loss(y, y_hat)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx=None):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        # compute metrics\n",
    "        val_loss =self.get_loss(y_hat, y)\n",
    "        acc = self.accuracy(torch.argmax(y_hat, dim=1), y)\n",
    "        auroc = self.AUROC(y_hat.cpu().detach(), y.cpu().detach())\n",
    "        #fpr, tpr, thresholds = self.ROC(y_hat, y)\n",
    "        #\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "        self.log('val_acc', acc, on_step=True, on_epoch=True, logger=True)\n",
    "        self.AUROC.update(y_hat.cpu().detach(), y.cpu().detach())\n",
    "        self.log(\"validation_auc\", self.AUROC, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        #self.log(\"val_auc\", valid_auc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "\n",
    "class HEEnsembleModel(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 ensembles_settings:dict={'efficientnetb7':3, 'resnext101':2}, \n",
    "                 n_classes:int=2,\n",
    "                 input_shape=(224,224)):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        models = []\n",
    "        self.n_models = 0\n",
    "        for name, number in ensembles_settings.items():\n",
    "            [models.append(\n",
    "                HEClassificationModel(model_name=name, \n",
    "                                      n_classes=2, \n",
    "                                      pretrain=True,\n",
    "                                      custom_classification_head=False\n",
    "                                     )\n",
    "                         ) for i in range(number)\n",
    "            ]\n",
    "            self.n_models += n_classes\n",
    "        self.ensemble_model = torch.nn.ModuleList(models)\n",
    "        self.classifier = torch.nn.Linear(self.n_models, n_classes)\n",
    "        #self.save_hyperparameters() # Uncomment to show error\n",
    "        # metrics\n",
    "        self.accuracy = torchmetrics.Accuracy()\n",
    "        #self.ROC = torchmetrics.ROC(num_classes=n_classes)\n",
    "        self.AUROC = torchmetrics.AUROC(num_classes=n_classes, pos_label=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.ensemble_model(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=1e-10)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def get_loss(self, y_hat, y):\n",
    "        #loss = nn.CrossEntropyLoss()   # does softmax for you (no need in classifcation)\n",
    "        #loss = nn.LogSoftmax()\n",
    "        #loss = F.nll_loss\n",
    "        if self.debug: print(y.size(), y.dtype, y_hat.size(), y_hat.dtype)\n",
    "        return F.cross_entropy(y_hat,  y)\n",
    "\n",
    "    def training_step(self, batch, batch_idx=None):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.get_loss(y_hat, y)\n",
    "        # training metrics\n",
    "        acc = self.accuracy(torch.argmax(y_hat, dim=1), y)\n",
    "        # optimize (done under the hoood)\n",
    "\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, logger=True)\n",
    "        return loss\n",
    "        #return self.get_loss(y, y_hat)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx=None):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        # compute metrics\n",
    "        val_loss =self.get_loss(y_hat, y)\n",
    "        acc = self.accuracy(torch.argmax(y_hat, dim=1), y)\n",
    "        auroc = self.AUROC(y_hat.cpu().detach(), y.cpu().detach())\n",
    "        #fpr, tpr, thresholds = self.ROC(y_hat, y)\n",
    "        #\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "        self.log('val_acc', acc, on_step=True, on_epoch=True, logger=True)\n",
    "        self.AUROC.update(y_hat.cpu().detach(), y.cpu().detach())\n",
    "        self.log(\"validation_auc\", self.AUROC, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        #self.log(\"val_auc\", valid_auc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZUgCx55pqolP"
   },
   "outputs": [],
   "source": [
    "# callbacks\n",
    "class PRMetrics(pl.Callback):\n",
    "    \"\"\" Custom callback to compute per-class PR & ROC curves\n",
    "    at the end of each training epoch\n",
    "    \"\"\"\n",
    "    def __init__(self,  val_samples, num_samples=32, class_names={'Non-responder':0, 'Responder':1}):    #generator=None, num_log_batches=1):\n",
    "        # self.generator = generator\n",
    "        # self.num_batches = num_log_batches\n",
    "        # # store full names of classes\n",
    "        # self.class_names = { v: k for k, v in generator.class_indices.items() }\n",
    "        # self.flat_class_names = [k for k, v in generator.class_indices.items()]\n",
    "\n",
    "        super().__init__()\n",
    "        self.num_samples = num_samples\n",
    "        self.class_names = class_names\n",
    "        self.val_imgs, self.val_labels = val_samples\n",
    "\n",
    "    def on_epoch_end(self, trainer, pl_module, logs={}):\n",
    "        # # collect validation data and ground truth labels from generator\n",
    "        # val_data, val_labels = zip(*(self.generator[i] for i in range(self.num_batches)))\n",
    "        # val_data, val_labels = np.vstack(val_data), np.vstack(val_labels)\n",
    "\n",
    "        # # use the trained model to generate predictions for the given number\n",
    "        # # of validation data batches (num_batches)\n",
    "        # val_predictions = self.model.predict(val_data)\n",
    "        # ground_truth_class_ids = val_labels.argmax(axis=1)\n",
    "        # Bring the tensors to CPU\n",
    "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
    "        val_labels = self.val_labels.to(device=pl_module.device)\n",
    "        # Get model prediction\n",
    "        preds = torch.argmax(pl_module(val_imgs), -1)\n",
    "        # Log precision-recall curve the key \"pr_curve\" is the id of the plot--do not change this if you want subsequent runs to show up on the same plot\n",
    "        wandb.log({\"roc_curve\" : wandb.plot.roc_curve(val_labels, preds, labels=self.class_names)})\n",
    "\n",
    "class ImagePredictionLogger(pl.Callback):\n",
    "    \"\"\" callback\"\"\"\n",
    "    def __init__(self, val_samples, num_samples=32):\n",
    "        super().__init__()\n",
    "        self.num_samples = num_samples\n",
    "        self.val_imgs, self.val_labels = val_samples\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        # Bring the tensors to CPU\n",
    "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
    "        val_labels = self.val_labels.to(device=pl_module.device)\n",
    "        # Get model prediction\n",
    "        logits = pl_module(val_imgs)\n",
    "        preds = torch.argmax(logits, -1)\n",
    "        # Log the images as wandb Image\n",
    "        trainer.logger.experiment.log({\n",
    "            \"examples\":[wandb.Image(x, caption=f\"Pred:{pred}, Label:{y}\") \n",
    "                           for x, pred, y in zip(val_imgs[:self.num_samples], \n",
    "                                                 preds[:self.num_samples], \n",
    "                                                 val_labels[:self.num_samples])]\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kl1KS1Qdq_05"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kinjz3AgaGjB"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from pytorch_lightning.callbacks import EarlyStopping, GradientAccumulationScheduler\n",
    "import pytorch_lightning as pl\n",
    "# logger\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "#\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvChBn4WJzWb"
   },
   "outputs": [],
   "source": [
    "class TRAIN_args:\n",
    "    batch_size = 4\n",
    "    test_batch_size = 1\n",
    "    epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gk2iGQLALW7W"
   },
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "    '''\n",
    "        Try resetting model weights to avoid\n",
    "        weight leakage.\n",
    "    '''\n",
    "    for layer in m.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            print(f'Reset trainable parameters of layer = {layer}')\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1aoYeC2oNT2A"
   },
   "outputs": [],
   "source": [
    "# DEFAULT (ie: no accumulated grads)\n",
    "cbs = [\n",
    "    pl.callbacks.ModelCheckpoint(monitor='val_loss', dirpath=PATH_ARGS.model_path,\n",
    "                                 filename='models-{epoch:02d}-{val_loss:.2f}', save_top_k=2, mode='min'),\n",
    "    EarlyStopping(monitor=\"val_loss\", min_delta=1e-7, patience=8, mode=\"min\"),\n",
    "    GradientAccumulationScheduler(scheduling={0: 8, 4: 4, 8: 1}),\n",
    "    PRMetrics(),\n",
    "]\n",
    "trainer = pl.Trainer(\n",
    "    #gpus=1, \n",
    "    devices=1,\n",
    "    logger=WandbLogger(project='AD-ensemble(draft)',  entity=\"3m-m\", job_type='train'),\n",
    "    max_epochs=TRAIN_args.epochs, callbacks=cbs)\n",
    "\n",
    "model = HEEnsembleModel(ensembles_settings={'efficientnetb7':3, 'resnext101':2}, \n",
    "                        input_shape=(224,224)\n",
    "                        n_classes=MODEL_ARGS.n_classes)\n",
    "datamodule = HEDataModule(batch_size=DATA_ARGS.batch_size)\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dBQBmVGE3u_M"
   },
   "outputs": [],
   "source": [
    "# train\n",
    "trainer.fit(model=model, datamodule=datamodule) \n",
    "# save with parameters\n",
    "#torch.save([model.kwargs, model.state_dict()], path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v65ctfW7HABS"
   },
   "source": [
    "### Prediction/submission"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "uUsLsFHLv8b8"
   },
   "source": [
    "test_loader = DataLoader(HEdatasets['test'], shuffle=True, batch_size=TRAIN_args.test_batch_size)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "dca68bea1ee5b3be888f6b0e1f9475265928937e00d73db3ed64c34751d2276f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
