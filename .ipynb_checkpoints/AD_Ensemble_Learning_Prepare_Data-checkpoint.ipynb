{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpO5NE34z3Ty"
   },
   "source": [
    "Data from: http://zhao-nas.bio.cmu.edu:5000/fsdownload/aBDx29J7H/Ensemble%20learning%20data_shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x_yg1scuis1b",
    "outputId": "1a17cac2-4e37-44b7-e7c5-d73608c9681d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m3m-m\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QCRR78hBY1Q7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# if hasattr(os, 'add_dll_directory'):\n",
    "#     openslide_dir = r\"C:\\Users\\Windows\\Downloads\\openslide-win64-20220811\\bin\"\n",
    "#     print(f\"Adding openslide dir at:{openslide_dir}\")\n",
    "#     with os.add_dll_directory(openslide_dir):\n",
    "#         import openslide\n",
    "# else:\n",
    "#     import openslide\n",
    "# from tiatoolbox.tools import patchextraction\n",
    "# from tiatoolbox.utils.misc import imread,  read_locations\n",
    "# from tiatoolbox.tools import stainnorm\n",
    "# from tiatoolbox import data\n",
    "# from tiatoolbox.wsicore.wsireader import WSIReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "783KVUhBVn9-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\anaconda3\\envs\\ensemble_vision\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import cv2 , os, numpy as np, torch, pandas as pd, tqdm as tqdm, PIL.Image as Image, time\n",
    "#from pylab import rcParams\n",
    "import datetime\n",
    "# \n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from pytorch_lightning.loops.fit_loop import FitLoop\n",
    "from pytorch_lightning.loops.loop import Loop\n",
    "#\n",
    "from numpy.lib.function_base import select\n",
    "from sklearn.preprocessing import LabelBinarizer, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "#import efficientnet_pytorch\n",
    "import pytorch_lightning as pl, torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "F3Rn6pJjXGPh",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__module__': '__main__', 'proj_path': WindowsPath('C:/data/MattM_Ensemble'), 'model_path': WindowsPath('C:/data/MattM_Ensemble/model_chkpts'), 'data_path': WindowsPath('C:/data'), 'dataindex_path': WindowsPath('C:/data/dataIndex.csv'), 'data_name': ['HE_RBG_Corp_images'], 'class_names': ['Responder', 'NonResponder'], '__dict__': <attribute '__dict__' of 'PATH_ARGS' objects>, '__weakref__': <attribute '__weakref__' of 'PATH_ARGS' objects>, '__doc__': None}\n"
     ]
    }
   ],
   "source": [
    "class PATH_ARGS:\n",
    "    proj_path = Path('C:/data/MattM_Ensemble').absolute()  # [CHANGE THIS for new environment]\n",
    "    model_path = proj_path/'model_chkpts'\n",
    "    # data path\n",
    "    #data_path = proj_path/'TestingData'   # Test path\n",
    "    #data_path = proj_path/\"Ensemble_learning data\"      # [CONFIRM THIS for new environment]\n",
    "    data_path = proj_path.parent\n",
    "    dataindex_path = data_path/'dataIndex.csv'\n",
    "    # Select data folders here\n",
    "    data_name = ['HE_RBG_Corp_images']\n",
    "    #data_name = ['HE images', 'HIPT_AGH_FluorescentImage_R1']\n",
    "    # 2 groups to classify\n",
    "    class_names = ['Responder','NonResponder']\n",
    "\n",
    "def mkdirifNE(p):\n",
    "    if not os.path.exists(p): os.mkdir(p)\n",
    "\n",
    "mkdirifNE(PATH_ARGS.model_path)\n",
    "\n",
    "def load_img(img_paths: list, is_mask=False):\n",
    "        \"\"\" load array from a list of image paths \"\"\"\n",
    "        if is_mask: flag = 0\n",
    "        else: flag = -1\n",
    "        return np.concatenate([np.expand_dims(cv2.imread(str(img_fp), flag), axis=0)\n",
    "                               for img_fp in img_paths.tolist()])\n",
    "def normalize(ratios):\n",
    "    \"\"\"normalize a list of ratios to sum to 1\"\"\"\n",
    "    return [r/sum(ratios) for r in ratios]\n",
    "print(PATH_ARGS.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "-_Ib2UzBOMBI",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class preprocessor:\n",
    "    \"\"\"\n",
    "    Preprocessing for generating tiling images from large FOV\n",
    "    Generate data indexer table to be passed to dataloader\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path:Path, debug:bool=False):\n",
    "        \"\"\" path to large images containing the class folders of images (non-resp , resp)\"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.debug = debug\n",
    "        # define names\n",
    "        self.x_im_col = 'x_img_path'\n",
    "        self.y_col = 'label'\n",
    "    \n",
    "    def main(self, selected_folders:list = None,\n",
    "             splits={'train':0.7, 'val':0.1, 'test':0.2},\n",
    "             patch_generator:str=\"basic\",\n",
    "             normalize_stain:bool=True\n",
    "             ):\n",
    "        \"\"\"\n",
    "        patch_generator: TIA or basic\n",
    "        \"\"\"\n",
    "        # start indexing\n",
    "        self._dataIndexer()\n",
    "        print(f\"Folders: {selected_folders}\")\n",
    "        self.generate_all_tiles_all(self.data_path, patch_generator=patch_generator,\n",
    "                                    selected_folders=selected_folders, normalize_stain=normalize_stain)\n",
    "        if self.debug: print(f\"Indexer shape:{self.data_index.shape}\\n columns: {self.data_index.columns}, \\nX col:{self.x_im_col}; y col:{self.y_col}\") \n",
    "        self.add_stratify_splits(self.data_index, splits=splits)\n",
    "        self.data_index.to_csv(self.data_path/'dataIndex-copy.csv')\n",
    "        print(f\"[INFO] Copy of dataIndx saved to {self.data_path}\")\n",
    "        return self.data_index\n",
    "        \n",
    "    \n",
    "    def generate_all_tiles_all(self, \n",
    "                               path2_input_img_dir:Path,\n",
    "                               patch_generator=\"basic\", \n",
    "                               selected_folders:list=[], \n",
    "                               patch_dims:tuple=(224,224), \n",
    "                               normalize_stain:bool=True) ->None:\n",
    "        \"\"\" \n",
    "        selected folders  list[str] \n",
    "            names of folders to be included\n",
    "        \"\"\"\n",
    "        for dirp in path2_input_img_dir.iterdir():  # ['HE', 'HIPT']\n",
    "            # dirs only + selected folders\n",
    "            if dirp.is_file() or str(dirp).startswith('.'): \n",
    "                continue\n",
    "            #if (selected_folders is None) or (not dirp.name in selected_folders): continue\n",
    "            mkdirifNE(dirp.parent/(dirp.stem+'_processed'))\n",
    "            for class_dirp in dirp.iterdir(): # ['Res', 'Non-res']\n",
    "                # Skip file and not selected\n",
    "                if class_dirp.is_file(): continue\n",
    "                # generate tiles\n",
    "                print(f\"[DEBUG] Directories:\\nclass dirp{class_dirp}\\ndirp:{dirp.parent/(dirp.name+'_processed')/class_dirp.name}\")\n",
    "                self.generate_all_tiles(class_dirp,\n",
    "                                        save_dir_path=dirp.parent/(dirp.name+'_processed')/class_dirp.name,\n",
    "                                        patch_generator=patch_generator,\n",
    "                                        patch_dims=patch_dims,\n",
    "                                        normalize_stain=normalize_stain)\n",
    "\n",
    "    def generate_all_tiles(self, input_img_dir:Path, \n",
    "                           save_dir_path:Path=None,\n",
    "                           patch_generator:str=\"basic\",\n",
    "                           normalize_stain: bool=True,\n",
    "                           patch_dims:tuple=(224,224),\n",
    "                           ) -> None:\n",
    "        if save_dir_path is None:\n",
    "            save_dir_path = input_img_dir/(input_img_dir.stem+\"_processed\")\n",
    "        mkdirifNE(save_dir_path)\n",
    "        print(f\"saving images to :{save_dir_path}\")\n",
    "        # iterate images\n",
    "        for N, img_fp in enumerate(input_img_dir.iterdir()):\n",
    "            # only images files\n",
    "            if not img_fp.is_file() or (img_fp.suffix!= '.png' and img_fp.suffix!= '.tif'): continue\n",
    "            if self.debug: print(f\"Prepare to generate tiles from {img_fp} to be saved to {save_dir_path}\")\n",
    "            # get tiles (generator)\n",
    "            ref_img = cv2.imread(str(img_fp))  #.astype('uint8')\n",
    "            print(f\"Input image no.:{N} of size {ref_img.shape}\")\n",
    "            \n",
    "            try:\n",
    "                if patch_generator==\"TIA\":\n",
    "                    img_tiles_gen = self.tile_images_TIA(ref_img, patch_dims=patch_dims)\n",
    "                else:\n",
    "                    img_tiles_gen = self.tile_images_basic(ref_img, patch_dims=patch_dims)\n",
    "            except Exception as e:\n",
    "                print(f\"Error {e} encountered, skipping {img_fp}\")\n",
    "            # normalize\n",
    "            if normalize_stain: normalizer = self.stain_normalizer(ref_img)\n",
    "            for tile_n, img_tile in enumerate(img_tiles_gen):                \n",
    "                save_fn = save_dir_path/f\"{img_fp.resolve().stem}_t{tile_n}{img_fp.resolve().suffix}\"\n",
    "                if self.debug: print(f\"Saving tile {tile_n} to {save_fn}\")\n",
    "                # add to index (relative_path)\n",
    "                if type(img_tile)==np.ndarray and img_tile.shape==patch_dims+(3,):\n",
    "                    self._dataIndexer(\n",
    "                        pd.DataFrame(data={\n",
    "                            'type':[input_img_dir.parent.stem], 'tissue': img_fp.name, self.x_im_col:[save_fn], self.y_col:[input_img_dir.stem]}, \n",
    "                            index=[save_fn])\n",
    "                            )\n",
    "                try:\n",
    "                    if save_fn.is_file():   # Skip exist\n",
    "                        if self.debug: print(f\"\\t\\tSKipped...exist.\"); \n",
    "                        time.sleep(0.001)\n",
    "                        continue\n",
    "                    if normalize_stain: \n",
    "                        img_tile = normalizer.transform(img_tile)\n",
    "                    # write tile\n",
    "                    im = Image.fromarray(img_tile).save(str(save_fn))\n",
    "                    time.sleep(0.001)\n",
    "                except:\n",
    "                    if self.debug: print(f\"Failed for: {save_fn}\")\n",
    "\n",
    "\n",
    "    def tile_images_TIA(self, input_img: np.array, patch_dims=(224,224), stride=None):\n",
    "        \"\"\" Tiling function from TIA \n",
    "        return generaor object \"\"\"\n",
    "        if not stride: stride = patch_dims\n",
    "        fixed_patch_extractor = patchextraction.get_patch_extractor(\n",
    "            input_img=input_img,  # input image path, numpy array, or WSI object\n",
    "            # locations_list=np.array(centroids_list),\n",
    "            method_name=\"slidingwindow\",  # also supports \"point\" and \"slidingwindow\"\n",
    "            patch_size=patch_dims,  # size of the patch to extract around the centroids from centroids_list\n",
    "            stride=stride,  # 250 pixels overlap in both axes\n",
    "            resolution=0,\n",
    "            units=\"level\",\n",
    "        )\n",
    "        return fixed_patch_extractor\n",
    "    \n",
    "    def tile_images_basic(self, im:np.array, patch_dims=(224,224)):\n",
    "        \"\"\" return generator object\"\"\"\n",
    "        M, N = patch_dims\n",
    "        for y in range(0, im.shape[1]-N, N):\n",
    "            for x in range(0,im.shape[0]-M, M):\n",
    "                yield im[x:x+M, y:y+N,:]\n",
    "    \n",
    "    def stain_normalizer(self, target_section_image, method_name:str='Reinhard'):\n",
    "        \"\"\" use entire section as input\n",
    "        target_section_image: np.array\n",
    "        \"\"\"\n",
    "        stain_normalizer = stainnorm.get_normalizer(method_name)\n",
    "        stain_normalizer.fit(target_section_image)\n",
    "        return stain_normalizer\n",
    "\n",
    "    def tissue_segmenter(self, input_img_path:str=None):\n",
    "        wsi = WSIReader.open(input_img=input_img_path, power=20)\n",
    "        if self.debug: print(wsi.info.as_dict())\n",
    "        wsi_thumb = wsi.slide_thumbnail(resolution=1.25, units=\"power\")\n",
    "        mask = wsi.tissue_mask(resolution=1.25, units=\"power\")\n",
    "        mask_thumb = mask.slide_thumbnail(\n",
    "            resolution=1.25, units=\"power\"\n",
    "        )  # extracting the mask_thumb at the same resolution as wsi_thumb\n",
    "        if self.debug: print(type(mask_thumb), mask_thumb.dtype, mask_thumb.shape)\n",
    "        pass\n",
    "\n",
    "    def add_stratify_splits(self, data_index:pd.DataFrame,\n",
    "                            splits:dict={'train':0.7, 'val':0.1, 'test':0.2}, stratify:bool= True):\n",
    "        '''stratify train test split'''\n",
    "        data_index_split = data_index.copy()\n",
    "        split_names = list(splits.keys())\n",
    "        for sp_name in split_names[:-1]:\n",
    "            # ttsplit & stratify \n",
    "            (_, _, _, _, ind_train, ind_test)  = train_test_split(\n",
    "                data_index_split[self.x_im_col], data_index_split[self.y_col], \n",
    "                data_index_split.index, stratify=data_index_split[self.y_col] if stratify else None, test_size=1-(splits[sp_name]/sum(splits.values())))\n",
    "            # set defined ï¼ˆ'train') set in data_index \n",
    "            data_index.loc[ind_train, 'set'] = sp_name\n",
    "            # remove training set\n",
    "            data_index_split = data_index_split.loc[ind_test]\n",
    "            splits.pop(sp_name)\n",
    "        # last type\n",
    "        data_index.loc[ind_test, 'set'] = split_names[-1]\n",
    "        # show group stats\n",
    "        print(\"Group stats:\\n\",data_index.groupby('set')['set'].apply(lambda x: len(x)))\n",
    "        return data_index\n",
    "    \n",
    "    def _dataIndexer(self, dataframe_row:pd.DataFrame=None, set_on:bool=True, ):\n",
    "        if hasattr(self, 'writing'):\n",
    "            if set_on:\n",
    "                # Initialized already\n",
    "                self.data_index = pd.concat([self.data_index, dataframe_row])\n",
    "                self.data_index.to_csv(self.data_path/'dataIndex.csv', mode='a', index=True, header=self._add_header)\n",
    "                self._add_header = False\n",
    "            else:\n",
    "                del self.writing\n",
    "        else: \n",
    "            # first start, initialize dataframe\n",
    "            if set_on: \n",
    "                self.writing = True\n",
    "                self._add_header = True\n",
    "                #\n",
    "                self.data_index = pd.DataFrame()\n",
    "                self.data_index.index.name = 'path'\n",
    "                self.data_index.to_csv(self.data_path/'dataIndex.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwI73Tjn56T6",
    "outputId": "088252a0-2e2d-48f7-ec9d-e48856a511f1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\data\n"
     ]
    }
   ],
   "source": [
    "# pass data folder \n",
    "print(PATH_ARGS.data_path)\n",
    "prep = preprocessor(PATH_ARGS.data_path, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders: ['HE_RBG_Corp_images']\n",
      "[DEBUG] Directories:\n",
      "class dirpC:\\data\\HE_RBG_Corp_images\\.ipynb_checkpoints\n",
      "dirp:C:\\data\\HE_RBG_Corp_images_processed\\.ipynb_checkpoints\n",
      "saving images to :C:\\data\\HE_RBG_Corp_images_processed\\.ipynb_checkpoints\n",
      "[DEBUG] Directories:\n",
      "class dirpC:\\data\\HE_RBG_Corp_images\\NonResponder\n",
      "dirp:C:\\data\\HE_RBG_Corp_images_processed\\NonResponder\n",
      "saving images to :C:\\data\\HE_RBG_Corp_images_processed\\NonResponder\n",
      "Input image no.:0 of size (3638, 3780, 3)\n",
      "Input image no.:1 of size (4701, 4701, 3)\n",
      "Input image no.:2 of size (4063, 4086, 3)\n",
      "Input image no.:3 of size (3993, 2468, 3)\n",
      "Input image no.:4 of size (2543, 5594, 3)\n",
      "Input image no.:5 of size (9372, 9953, 3)\n",
      "Input image no.:6 of size (18890, 5014, 3)\n"
     ]
    }
   ],
   "source": [
    "data_index_df = prep.main(\n",
    "    selected_folders=PATH_ARGS.data_name, splits={'train':0.7, 'val':0.1, 'test':0.2}, \n",
    "    patch_generator=\"basic\",\n",
    "    patch_dims=(224,224),\n",
    "    normalize_stain=False,); \n",
    "data_index_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IC1aUI5cbwld",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_index_df = pd.read_csv(PATH_ARGS.data_path/'dataIndex.csv', index_col=0)\n",
    "print(data_index_df['set'].unique())\n",
    "print(data_index_df['set'].value_counts())\n",
    "data_index_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TtND_hWkZyQU",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_images(data_index_df,):\n",
    "    target_shape = (224, 224, 3)\n",
    "    for img_fp in data_index_df.x_img_path.to_list():\n",
    "        if np.asarray(Image.open(img_fp)).shape!=target_shape:\n",
    "            print(f\"Incorrect instance at:{img_fp}\")\n",
    "            break\n",
    "    print(\"Passed.\")\n",
    "#check_images(data_index_df)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "dca68bea1ee5b3be888f6b0e1f9475265928937e00d73db3ed64c34751d2276f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
