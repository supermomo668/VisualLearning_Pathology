{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpO5NE34z3Ty"
   },
   "source": [
    "Data from: http://zhao-nas.bio.cmu.edu:5000/fsdownload/aBDx29J7H/Ensemble%20learning%20data_shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QCRR78hBY1Q7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# if hasattr(os, 'add_dll_directory'):\n",
    "#     openslide_dir = r\"C:\\Users\\Windows\\Downloads\\openslide-win64-20220811\\bin\"\n",
    "#     print(f\"Adding openslide dir at:{openslide_dir}\")\n",
    "#     with os.add_dll_directory(openslide_dir):\n",
    "#         import openslide\n",
    "# else:\n",
    "#     import openslide\n",
    "# from tiatoolbox.tools import patchextraction\n",
    "# from tiatoolbox.utils.misc import imread,  read_locations\n",
    "# from tiatoolbox.tools import stainnorm\n",
    "# from tiatoolbox import data\n",
    "# from tiatoolbox.wsicore.wsireader import WSIReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "783KVUhBVn9-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/windows/anaconda3/envs/vision/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import cv2 , os, numpy as np, torch, pandas as pd, tqdm as tqdm, PIL.Image as Image, time\n",
    "#from pylab import rcParams\n",
    "import datetime, copy\n",
    "# \n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from pytorch_lightning.loops.fit_loop import FitLoop\n",
    "from pytorch_lightning.loops.loop import Loop\n",
    "#\n",
    "from numpy.lib.function_base import select\n",
    "from sklearn.preprocessing import LabelBinarizer, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "#import efficientnet_pytorch\n",
    "import pytorch_lightning as pl, torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "F3Rn6pJjXGPh",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__module__': '__main__', 'proj_path': PosixPath('/mnt/c/data/MattM_Ensemble'), 'model_path': PosixPath('/mnt/c/data/MattM_Ensemble/model_chkpts'), 'data_path': PosixPath('/mnt/c/data'), 'data_name': ['HE_RBG_Corp_images'], 'dataindex_path': PosixPath('/mnt/c/data/dataIndex.csv'), 'class_names': ['Responder', 'NonResponder'], '__dict__': <attribute '__dict__' of 'PATH_ARGS' objects>, '__weakref__': <attribute '__weakref__' of 'PATH_ARGS' objects>, '__doc__': None}\n"
     ]
    }
   ],
   "source": [
    "prefix=Path('/mnt/c/data/MattM_Ensemble')\n",
    "\n",
    "class PATH_ARGS:\n",
    "    proj_path = Path('./').absolute()  # [CHANGE THIS for new environment]\n",
    "    model_path = proj_path/'model_chkpts'\n",
    "    # data path\n",
    "    #data_path = proj_path/'TestingData'   # Test path\n",
    "    #data_path = proj_path/\"Ensemble_learning data\"      # [CONFIRM THIS for new environment]\n",
    "    data_path = proj_path.parent\n",
    "    data_name = ['HE_RBG_Corp_images']\n",
    "    dataindex_path = data_path/'dataIndex.csv'\n",
    "    # Select data folders here\n",
    "    #data_name = ['HE images', 'HIPT_AGH_FluorescentImage_R1']\n",
    "    # 2 groups to classify\n",
    "    class_names = ['Responder','NonResponder']\n",
    "\n",
    "def mkdirifNE(p):\n",
    "    if not os.path.exists(p): os.mkdir(p)\n",
    "\n",
    "mkdirifNE(PATH_ARGS.model_path)\n",
    "\n",
    "def load_img(img_paths: list, is_mask=False):\n",
    "        \"\"\" load array from a list of image paths \"\"\"\n",
    "        if is_mask: flag = 0\n",
    "        else: flag = -1\n",
    "        return np.concatenate([np.expand_dims(cv2.imread(str(img_fp), flag), axis=0)\n",
    "                               for img_fp in img_paths.tolist()])\n",
    "def normalize(ratios):\n",
    "    \"\"\"normalize a list of ratios to sum to 1\"\"\"\n",
    "    return [r/sum(ratios) for r in ratios]\n",
    "print(PATH_ARGS.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-_Ib2UzBOMBI",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class preprocessor:\n",
    "    \"\"\"\n",
    "    Preprocessing for generating tiling images from large FOV\n",
    "    Generate data indexer table to be passed to dataloader\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path:Path, debug:bool=False):\n",
    "        \"\"\" path to large images containing the class folders of images (non-resp , resp)\"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.debug = debug\n",
    "        # define names\n",
    "        self.x_im_col = 'x_img_path'\n",
    "        self.y_col = 'label'\n",
    "        self.index_cols = ['parent_path','type', 'tissue', self.x_im_col]\n",
    "        # 2 indexers for source/tile imgs\n",
    "        self.idxer_source = dataIndexer(self.data_path/'dataIndex_source.csv', columns=self.index_cols[:-1]+[self.y_col], index_cols=self.index_cols[:-1])\n",
    "        self.idxer_tile = dataIndexer(self.data_path/'dataIndex_tile.csv', columns=self.index_cols+[self.y_col], index_cols=self.index_cols)\n",
    "    \n",
    "    def main(self, selected_folders:list = None,\n",
    "             splits={'train':0.7, 'val':0.1, 'test':0.2},\n",
    "             patch_generator:str=\"basic\",\n",
    "             patch_dims:tuple=(224,224), \n",
    "             normalize_stain:bool=True\n",
    "             ):\n",
    "        \"\"\"\n",
    "        patch_generator: TIA or basic\n",
    "        \"\"\"\n",
    "        # start indexing\n",
    "        \n",
    "        print(f\"Folders: {selected_folders}\")\n",
    "        self.generate_all_tiles_all(self.data_path, \n",
    "                                    patch_generator=patch_generator,\n",
    "                                    selected_folders=selected_folders, \n",
    "                                    patch_dims=patch_dims,\n",
    "                                    normalize_stain=normalize_stain)\n",
    "        dataindex_source = pd.read_csv(self.idxer_source.fp_csv, index_col=self.idxer_source.index_cols)\n",
    "        dataindex_tile = pd.read_csv(self.idxer_tile.fp_csv, index_col=self.idxer_tile.index_cols)\n",
    "        if self.debug: print(f\"Indexer shape:{dataindex_tile.shape}\\n columns: {dataindex_tile.columns}\")\n",
    "        print(f\"Generate stratifieid splits.\")\n",
    "        dataindex_source = self.add_stratify_splits(dataindex_source, splits=splits.copy())\n",
    "        dataindex_tile = self.add_stratify_splits(dataindex_tile, splits=splits.copy())\n",
    "        dataindex_source.to_csv(self.idxer_source.fp_csv)\n",
    "        dataindex_tile.to_csv(self.idxer_tile.fp_csv)\n",
    "        print(f\"[INFO] Copy of dataIndex saved to {self.data_path}\")\n",
    "        return dataindex_source, dataindex_tile\n",
    "        \n",
    "    \n",
    "    def generate_all_tiles_all(self, \n",
    "                               path2_input_img_dir:Path,\n",
    "                               patch_generator=\"basic\", \n",
    "                               selected_folders:list=[], \n",
    "                               patch_dims:tuple=(224,224), \n",
    "                               normalize_stain:bool=True) ->None:\n",
    "        \"\"\" \n",
    "        selected folders  list[str] \n",
    "            names of folders to be included\n",
    "        \"\"\"\n",
    "        for dirp in path2_input_img_dir.iterdir():  # ['HE', 'HIPT']\n",
    "            # dirs only + selected folders\n",
    "            if dirp.is_file() or dirp.name not in selected_folders: \n",
    "                continue\n",
    "            print(f\"Generating tiles for data folder:{dirp}\")\n",
    "            #if (selected_folders is None) or (not dirp.name in selected_folders): continue\n",
    "            mkdirifNE(dirp.parent/(dirp.stem+'_processed'))\n",
    "            for class_dirp in dirp.iterdir(): # ['Res', 'Non-res']\n",
    "                # Skip file and not selected\n",
    "                if class_dirp.is_file(): continue\n",
    "                # generate tiles\n",
    "                print(f\"[DEBUG] Directories:\\nclass dirp{class_dirp}\\ndirp:{dirp.parent/(dirp.name+'_processed')/class_dirp.name}\")\n",
    "                self.generate_all_tiles(class_dirp,\n",
    "                                        save_dir_path=dirp.parent/(dirp.name+'_processed')/class_dirp.name,\n",
    "                                        patch_generator=patch_generator,\n",
    "                                        patch_dims=patch_dims,\n",
    "                                        normalize_stain=normalize_stain)\n",
    "\n",
    "    def generate_all_tiles(self, input_img_dir:Path, \n",
    "                           save_dir_path:Path=None,\n",
    "                           patch_generator:str=\"basic\",\n",
    "                           normalize_stain: bool=True,\n",
    "                           patch_dims:tuple=(224,224),\n",
    "                           ) -> None:\n",
    "        if save_dir_path is None:\n",
    "            save_dir_path = input_img_dir/(input_img_dir.stem+\"_processed\")\n",
    "        mkdirifNE(save_dir_path)\n",
    "        # iterate (tissue) images from input_img_dir\n",
    "        for N, img_fp in enumerate(input_img_dir.iterdir()):  \n",
    "            print(f\"Folder:{img_fp}\")\n",
    "            # only images files\n",
    "            if not img_fp.is_file() or (img_fp.suffix!= '.png' and img_fp.suffix!= '.tif'): continue\n",
    "            if self.debug: print(f\"Prepare to generate tiles from {img_fp} to be saved to {save_dir_path}\")\n",
    "            # get tiles (generator)\n",
    "            ref_img = cv2.imread(str(img_fp))  #.astype('uint8')\n",
    "            print(f\"Input image no.:{N} of size {ref_img.shape}\")\n",
    "                # tile methods\n",
    "            try:\n",
    "                if patch_generator==\"TIA\":\n",
    "                    img_tiles_gen = self.tile_images_TIA(ref_img, patch_dims=patch_dims)\n",
    "                else:\n",
    "                    img_tiles_gen = self.tile_images_basic(ref_img, patch_dims=patch_dims)\n",
    "            except Exception as e:\n",
    "                print(f\"Error {e} encountered, skipping {img_fp}\")\n",
    "            # normalize\n",
    "            if normalize_stain: normalizer = self.stain_normalizer(ref_img)\n",
    "            # idx source img\n",
    "            self.idxer_source.write(\n",
    "                        pd.DataFrame(data={\n",
    "                            'parent_path':[input_img_dir/input_img_dir.stem], 'type':[input_img_dir.parent.stem], \n",
    "                            'tissue': [img_fp.name], self.y_col:[input_img_dir.stem]}\n",
    "                        )\n",
    "            )\n",
    "            for tile_n, img_tile in enumerate(img_tiles_gen):                \n",
    "                save_fn = save_dir_path/f\"{img_fp.resolve().stem}_t{tile_n}{img_fp.resolve().suffix}\"\n",
    "                if self.debug: print(f\"Saving tile {tile_n} to {save_fn}\")\n",
    "                # add to index (relative_path)\n",
    "                if type(img_tile)==np.ndarray and img_tile.shape==patch_dims+(3,):\n",
    "                    self.idxer_tile.write(\n",
    "                        pd.DataFrame(data={\n",
    "                            'parent_path':[save_fn.parent], 'type':[input_img_dir.parent.stem], \n",
    "                            'tissue': [img_fp.name], self.x_im_col:[save_fn.name], self.y_col:[input_img_dir.stem]}\n",
    "                        )\n",
    "                    )\n",
    "                try:\n",
    "                    if save_fn.is_file():   # Skip exist\n",
    "                        if self.debug: print(f\"\\t\\tSKipped...exist.\"); \n",
    "                        time.sleep(0.001)\n",
    "                        continue\n",
    "                    if normalize_stain: \n",
    "                        img_tile = normalizer.transform(img_tile)\n",
    "                    # write tile\n",
    "                    im = Image.fromarray(img_tile).save(str(save_fn))\n",
    "                    time.sleep(0.001)\n",
    "                except:\n",
    "                    if self.debug: print(f\"Failed for: {save_fn}\")\n",
    "\n",
    "\n",
    "    def tile_images_TIA(self, input_img: np.array, patch_dims=(224,224), stride=None):\n",
    "        \"\"\" Tiling function from TIA \n",
    "        return generaor object \"\"\"\n",
    "        if not stride: stride = patch_dims\n",
    "        fixed_patch_extractor = patchextraction.get_patch_extractor(\n",
    "            input_img=input_img,  # input image path, numpy array, or WSI object\n",
    "            # locations_list=np.array(centroids_list),\n",
    "            method_name=\"slidingwindow\",  # also supports \"point\" and \"slidingwindow\"\n",
    "            patch_size=patch_dims,  # size of the patch to extract around the centroids from centroids_list\n",
    "            stride=stride,  # 250 pixels overlap in both axes\n",
    "            resolution=0,\n",
    "            units=\"level\",\n",
    "        )\n",
    "        return fixed_patch_extractor\n",
    "    \n",
    "    def tile_images_basic(self, im:np.array, patch_dims=(224,224)):\n",
    "        \"\"\" return generator object\"\"\"\n",
    "        M, N = patch_dims\n",
    "        for y in range(0, im.shape[1]-N, N):\n",
    "            for x in range(0,im.shape[0]-M, M):\n",
    "                yield im[x:x+M, y:y+N,:]\n",
    "    \n",
    "    def stain_normalizer(self, target_section_image, method_name:str='Reinhard'):\n",
    "        \"\"\" use entire section as input\n",
    "        target_section_image: np.array\n",
    "        \"\"\"\n",
    "        stain_normalizer = stainnorm.get_normalizer(method_name)\n",
    "        stain_normalizer.fit(target_section_image)\n",
    "        return stain_normalizer\n",
    "\n",
    "    def tissue_segmenter(self, input_img_path:str=None):\n",
    "        wsi = WSIReader.open(input_img=input_img_path, power=20)\n",
    "        if self.debug: print(wsi.info.as_dict())\n",
    "        wsi_thumb = wsi.slide_thumbnail(resolution=1.25, units=\"power\")\n",
    "        mask = wsi.tissue_mask(resolution=1.25, units=\"power\")\n",
    "        mask_thumb = mask.slide_thumbnail(\n",
    "            resolution=1.25, units=\"power\"\n",
    "        )  # extracting the mask_thumb at the same resolution as wsi_thumb\n",
    "        if self.debug: print(type(mask_thumb), mask_thumb.dtype, mask_thumb.shape)\n",
    "        pass\n",
    "\n",
    "    def add_stratify_splits(self, data_index: pd.DataFrame,\n",
    "                            splits:dict={'train':0.7, 'val':0.1, 'test':0.2}, stratify:bool= True):\n",
    "        '''stratify train test split'''\n",
    "        data_index_split = data_index.copy()\n",
    "        split_names = list(splits.keys())\n",
    "        print(data_index_split.shape)\n",
    "        for sp_name in split_names[:-1]:\n",
    "            # ttsplit & stratify \n",
    "            label_col = data_index_split[self.y_col]\n",
    "            (_, _, _, _, ind_train, ind_test)  = train_test_split(\n",
    "                np.arange(len(label_col)), label_col, \n",
    "                label_col.index, stratify=label_col if stratify else None, test_size=1-(splits[sp_name]/sum(splits.values()))\n",
    "            )\n",
    "            # set defined ï¼ˆ'train') set in data_index \n",
    "            print(f\"Split set:{sp_name}\")\n",
    "            data_index.loc[ind_train, 'set'] = sp_name\n",
    "            # remove training set\n",
    "            data_index_split = data_index_split.loc[ind_test]\n",
    "            splits.pop(sp_name)\n",
    "        # last type\n",
    "        data_index.loc[ind_test, 'set'] = split_names[-1]\n",
    "        # show group stats\n",
    "        print(\"Group stats:\\n\",data_index.groupby('set')['set'].apply(lambda x: len(x)))\n",
    "        return data_index\n",
    "\n",
    "class dataIndexer:\n",
    "    def __init__(self, fp_csv, columns=[], index_cols=[]):\n",
    "        self.fp_csv = fp_csv\n",
    "        self.index_cols = index_cols\n",
    "        data_index = pd.DataFrame(dict.fromkeys(columns), index=[]).set_index(index_cols)  # all are index except y_col\n",
    "        data_index.to_csv(fp_csv)\n",
    "        \n",
    "    def write(self, dataframe_row, on:bool=True):\n",
    "        dataframe_row.set_index(self.index_cols).to_csv(self.fp_csv, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwI73Tjn56T6",
    "outputId": "088252a0-2e2d-48f7-ec9d-e48856a511f1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/data\n",
      "['parent_path', 'type', 'tissue', 'x_img_path']\n"
     ]
    }
   ],
   "source": [
    "# pass data folder \n",
    "print(PATH_ARGS.data_path)\n",
    "prep = preprocessor(PATH_ARGS.data_path, debug=False)\n",
    "print(prep.index_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parent_path</th>\n",
       "      <th>type</th>\n",
       "      <th>tissue</th>\n",
       "      <th>x_img_path</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">/mnt/c/data/HE_RBG_Corp_images_processed/NonResponder</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">HE_RBG_Corp_images</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">NA-24_0000023786_2021-03-22 09_49_45 - Series 1 (1, x=16274, y=23991, w=3780, h=3638).tif</th>\n",
       "      <th>NA-24_0000023786_2021-03-22 09_49_45 - Series 1 (1, x=16274, y=23991, w=3780, h=3638)_t0.tif</th>\n",
       "      <td>NonResponder</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA-24_0000023786_2021-03-22 09_49_45 - Series 1 (1, x=16274, y=23991, w=3780, h=3638)_t1.tif</th>\n",
       "      <td>NonResponder</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                    label  \\\n",
       "parent_path                                        type               tissue                                             x_img_path                                                         \n",
       "/mnt/c/data/HE_RBG_Corp_images_processed/NonRes... HE_RBG_Corp_images NA-24_0000023786_2021-03-22 09_49_45 - Series 1... NA-24_0000023786_2021-03-22 09_49_45 - Series 1...  NonResponder   \n",
       "                                                                                                                         NA-24_0000023786_2021-03-22 09_49_45 - Series 1...  NonResponder   \n",
       "\n",
       "                                                                                                                                                                              set  \n",
       "parent_path                                        type               tissue                                             x_img_path                                                \n",
       "/mnt/c/data/HE_RBG_Corp_images_processed/NonRes... HE_RBG_Corp_images NA-24_0000023786_2021-03-22 09_49_45 - Series 1... NA-24_0000023786_2021-03-22 09_49_45 - Series 1...  test  \n",
       "                                                                                                                         NA-24_0000023786_2021-03-22 09_49_45 - Series 1...  test  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_splits = {'train':0.7, 'val':0.1, 'test':0.2}\n",
    "data_index_df = prep.main(\n",
    "    selected_folders=PATH_ARGS.data_name, splits=tt_splits, \n",
    "    patch_generator=\"basic\",\n",
    "    patch_dims=(224,224),\n",
    "    normalize_stain=False,); \n",
    "data_index_df[1].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "IC1aUI5cbwld",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['label', 'set'], dtype='object') (177, 2) ['parent_path', 'type', 'tissue']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parent_path</th>\n",
       "      <th>type</th>\n",
       "      <th>tissue</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">/mnt/c/data/HE_RBG_Corp_images_processed/NonResponder</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">HE_RBG_Corp_images</th>\n",
       "      <th>NA-24_0000023786_2021-03-22 09_49_45 - Series 1 (1, x=16274, y=23991, w=3780, h=3638).tif</th>\n",
       "      <td>NonResponder</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA-24_0000023786_2021-03-22 09_49_45 - Series 1 (1, x=16466, y=14955, w=4701, h=4701).tif</th>\n",
       "      <td>NonResponder</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                 label  \\\n",
       "parent_path                                        type               tissue                                                             \n",
       "/mnt/c/data/HE_RBG_Corp_images_processed/NonRes... HE_RBG_Corp_images NA-24_0000023786_2021-03-22 09_49_45 - Series 1...  NonResponder   \n",
       "                                                                      NA-24_0000023786_2021-03-22 09_49_45 - Series 1...  NonResponder   \n",
       "\n",
       "                                                                                                                            set  \n",
       "parent_path                                        type               tissue                                                     \n",
       "/mnt/c/data/HE_RBG_Corp_images_processed/NonRes... HE_RBG_Corp_images NA-24_0000023786_2021-03-22 09_49_45 - Series 1...  train  \n",
       "                                                                      NA-24_0000023786_2021-03-22 09_49_45 - Series 1...  train  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_index_df = pd.read_csv(PATH_ARGS.data_path/'dataIndex_source.csv', index_col=prep.idxer_source.index_cols)\n",
    "print(data_index_df.columns, data_index_df.shape, prep.idxer_source.index_cols)\n",
    "data_index_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_index_df.index = data_index_df.index.set_levels(data_index_df.index.levels[0].str.replace(r'\\\\',r'/').str.replace(r'C:/data',r'/mnt/c/data'), level=0)\n",
    "data_index_df.head(2)\n",
    "data_index_df.to_csv(PATH_ARGS.data_path/(PATH_ARGS.data_name[0]+'_processed')/'dataIndex(ubuntu).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TtND_hWkZyQU",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_images(data_index_df,):\n",
    "    target_shape = (224, 224, 3)\n",
    "    for img_fp in data_index_df.x_img_path.to_list():\n",
    "        if np.asarray(Image.open(img_fp)).shape!=target_shape:\n",
    "            print(f\"Incorrect instance at:{img_fp}\")\n",
    "            break\n",
    "    print(\"Passed.\")\n",
    "#check_images(data_index_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "dca68bea1ee5b3be888f6b0e1f9475265928937e00d73db3ed64c34751d2276f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
