{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpO5NE34z3Ty"
   },
   "source": [
    "Data from: http://zhao-nas.bio.cmu.edu:5000/fsdownload/aBDx29J7H/Ensemble%20learning%20data_shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N_GBOIxuOFq8",
    "outputId": "54418c39-8744-4654-8965-c7a0b986dd52"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m3m-m\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install wandb\n",
    "# !pip install pytorch_lightning\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "783KVUhBVn9-"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2 , os, numpy as np, torch, pandas as pd, tqdm as tqdm, PIL.Image as Image, time, IPython\n",
    "#from pylab import rcParams\n",
    "import datetime\n",
    "# \n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "#import torchvision.transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from pytorch_lightning.loops.fit_loop import FitLoop\n",
    "from pytorch_lightning.loops.loop import Loop\n",
    "from albumentations.pytorch.transforms import ToTensorV2 \n",
    "#\n",
    "from numpy.lib.function_base import select\n",
    "from sklearn.preprocessing import LabelBinarizer, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "import pytorch_lightning as pl, torchmetrics\n",
    "import albumentations as A\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "F3Rn6pJjXGPh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__module__': '__main__', 'proj_path': PosixPath('/mnt/c/data/MattM_Ensemble'), 'model_path': PosixPath('/mnt/c/data/MattM_Ensemble/model_chkpts'), 'data_path': PosixPath('/mnt/c/data'), 'data_name': ['HE_RBG_Corp_images'], 'dataindex_fn': PosixPath('/mnt/c/data/dataIndex_source.csv'), 'dataindex_path': PosixPath('/mnt/c/data/dataIndex_source.csv'), 'class_names': ['Responder', 'NonResponder'], '__dict__': <attribute '__dict__' of 'PATH_ARGS' objects>, '__weakref__': <attribute '__weakref__' of 'PATH_ARGS' objects>, '__doc__': None}\n"
     ]
    }
   ],
   "source": [
    "class PATH_ARGS:\n",
    "    proj_path = Path('./').absolute()  # [CHANGE THIS for new environment]\n",
    "    model_path = proj_path/'model_chkpts'\n",
    "    # data path\n",
    "    #data_path = proj_path/'TestingData'   # Test path\n",
    "    #data_path = proj_path/'Ensemble_learning data'      # [CONFIRM THIS for new environment]\n",
    "    data_path = proj_path.parent\n",
    "    # 2 types of images (HE  FISH)\n",
    "    data_name = ['HE_RBG_Corp_images']\n",
    "    dataindex_fn = data_path/'dataIndex_source.csv'\n",
    "    dataindex_path = data_path/dataindex_fn\n",
    "    #data_name = ['HE images', 'HIPT_AGH_FluorescentImage_R1']\n",
    "    # 2 groups to classify\n",
    "    class_names = ['Responder','NonResponder']\n",
    "    \n",
    "print(PATH_ARGS.__dict__)\n",
    "def mkdirifNE(p):\n",
    "    if not os.path.exists(p): os.mkdir(p)\n",
    "\n",
    "mkdirifNE(PATH_ARGS.model_path)\n",
    "\n",
    "def load_img(img_paths: list, is_mask=False):\n",
    "    \"\"\" load array from a list of image paths \"\"\"\n",
    "    if is_mask: flag = 0\n",
    "    else: flag = -1\n",
    "    return np.concatenate([np.expand_dims(cv2.imread(str(img_fp), flag), axis=0)\n",
    "                           for img_fp in img_paths.tolist()])\n",
    "def normalize(ratios):\n",
    "    \"\"\"normalize a list of ratios to sum to 1\"\"\"\n",
    "    return [r/sum(ratios) for r in ratios]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IC1aUI5cbwld"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parent_path</th>\n",
       "      <th>type</th>\n",
       "      <th>tissue</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">/mnt/c/data/HE_RBG_Corp_images/NonResponder</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">HE_RBG_Corp_images</th>\n",
       "      <th>NA-24_0000023786_2021-03-22 09_49_45 - Series 1 (1, x=16274, y=23991, w=3780, h=3638).tif</th>\n",
       "      <td>NonResponder</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA-24_0000023786_2021-03-22 09_49_45 - Series 1 (1, x=16466, y=14955, w=4701, h=4701).tif</th>\n",
       "      <td>NonResponder</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                          label  \\\n",
       "parent_path                                 type               tissue                                                             \n",
       "/mnt/c/data/HE_RBG_Corp_images/NonResponder HE_RBG_Corp_images NA-24_0000023786_2021-03-22 09_49_45 - Series 1...  NonResponder   \n",
       "                                                               NA-24_0000023786_2021-03-22 09_49_45 - Series 1...  NonResponder   \n",
       "\n",
       "                                                                                                                     set  \n",
       "parent_path                                 type               tissue                                                     \n",
       "/mnt/c/data/HE_RBG_Corp_images/NonResponder HE_RBG_Corp_images NA-24_0000023786_2021-03-22 09_49_45 - Series 1...  train  \n",
       "                                                               NA-24_0000023786_2021-03-22 09_49_45 - Series 1...  train  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_index_df = pd.read_csv(PATH_ARGS.dataindex_path, index_col=list(range(3)))\n",
    "# print(data_index_df['set'].unique())\n",
    "# print(data_index_df['set'].value_counts())\n",
    "data_index_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjnyh2KKfp3L"
   },
   "source": [
    "### Dataloader - loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ADUtils.data import *\n",
    "from ADUtils.models import *\n",
    "from ADUtils.callbacks import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "oVqkEUQlftyf"
   },
   "outputs": [],
   "source": [
    "class META_ARGS:\n",
    "    RANDOM_SEED = 42\n",
    "    INPUT_DIM = (224,224)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class DATA_ARGS:\n",
    "    num_classes = 2\n",
    "    batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "Rvj6sDvItzfJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1056, 3, 112, 112])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "HE_data = HEData(dataindex_df=pd.read_csv(PATH_ARGS.dataindex_path, index_col=list(range(3))), patch_size=112, transform=get_transforms()['train'])\n",
    "HE_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug mode:False\n",
      "Setup dataindex:Index(['label', 'set'], dtype='object')\n",
      "torch.Size([3510, 3, 112, 112]) torch.Size([3510])\n"
     ]
    }
   ],
   "source": [
    "datamodule = HEDataModule(dataindex_path=PATH_ARGS.dataindex_fn, index_cols=['parent_path', 'type', 'tissue'], patch_size=112, batch_size=1, debug=False)\n",
    "datamodule.setup()\n",
    "data_loader = datamodule.train_dataloader()\n",
    "for x, y in data_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-2zwr80fr_0"
   },
   "source": [
    "### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BZjWd492DsUb"
   },
   "outputs": [],
   "source": [
    "# model and train args\n",
    "class MODEL_ARGS:\n",
    "    n_classes = len(PATH_ARGS.class_names)\n",
    "    \n",
    "class TRAIN_ARGS:\n",
    "    batch_size = DATA_ARGS.batch_size\n",
    "    epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import EfficientNet_B7_Weights, ResNeXt101_32X8D_Weights, MobileNet_V3_Large_Weights, ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ADUtils.data import *\n",
    "from ADUtils.models import HEClassificationModel\n",
    "from ADUtils.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "gcE8La0ftMU4"
   },
   "outputs": [],
   "source": [
    "# returns the size of the output tensor going into Linear layer from the conv block.\n",
    "def _get_conv_output(self, shape):\n",
    "    batch_size = 1\n",
    "    input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
    "\n",
    "    output_feat = self._forward_features(input) \n",
    "    n_size = output_feat.data.view(batch_size, -1).size(1)\n",
    "    return n_size\n",
    "    \n",
    "#from torch._C import device\n",
    "class HEClassificationModel(pl.LightningModule):\n",
    "    def __init__(self, model_name:str, n_classes:int=2, pretrain:bool=True,\n",
    "                 custom_classification_head:bool=False, input_size:tuple=(224,224), debug:bool=False):\n",
    "        super().__init__()\n",
    "        print(f\"Using pre-trained head:{model_name}\")\n",
    "        avail_models =  ['mobilenetv3','resnext101','efficientnetb7','resnet50']\n",
    "        assert model_name in ['mobilenetv3','resnext101','efficientnetb7','resnet50'], f\"Must be one of {avail_models}\"\n",
    "        self.debug = debug\n",
    "        self.n_classes = n_classes\n",
    "        self.custom_classification_head = custom_classification_head\n",
    "        # Step 1: Initialize model with the weights\n",
    "        if model_name == 'mobilenetv3':\n",
    "            self.model = models.mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.IMAGENET1K_V2 if pretrain else None)\n",
    "        elif model_name == 'resnext101':\n",
    "            self.model = models.resnext101_32x8d(weights=ResNeXt101_32X8D_Weights.IMAGENET1K_V1 if pretrain else None)\n",
    "        elif model_name == 'efficientnetb7':\n",
    "            self.model = models.efficientnet_b7(weights=EfficientNet_B7_Weights.IMAGENET1K_V1 if pretrain else None)\n",
    "        elif model_name =='resnet50':\n",
    "            self.model = models.resnet50(pretrained=ResNet50_Weights.IMAGENET1K_V2 if pretrain else None)\n",
    "        # replace/remove head\n",
    "        removed = list(self.model.children())[:-1]\n",
    "        self.model_base = torch.nn.Sequential(*removed)  \n",
    "        in_feats = self._get_output_feat(self.model_base, input_size)\n",
    "            # head\n",
    "        if self.custom_classification_head:\n",
    "            self.model_head = self.classification_head()\n",
    "        else:\n",
    "            self.model_head = nn.Sequential(nn.Flatten(),\n",
    "                                            nn.Linear(in_features=in_feats, out_features=self.n_classes, bias=True),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.LogSoftmax(dim=1) if n_classes>2 else nn.Sigmoid(),\n",
    "                                           )\n",
    "        self.model = torch.nn.Sequential(self.model_base, self.model_head)\n",
    "            #self.model_head.to(device=META_ARGS.device)     \n",
    "        # metrics\n",
    "        self.accuracy = torchmetrics.Accuracy()\n",
    "        #self.ROC = torchmetrics.ROC(num_classes=n_classes)\n",
    "        self.AUROC = torchmetrics.AUROC(num_classes=n_classes, pos_label=1)\n",
    "    \n",
    "    def _get_output_feat(self, model, in_shape=(224,224)):\n",
    "        x = torch.randn((3,)+in_shape)\n",
    "        return model(x.unsqueeze(0)).flatten().size()[0]\n",
    "\n",
    "    def _forward_feature_extract(self, x):\n",
    "        return self.model_base(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "#         #x = self.model_head(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = F.relu(nn.Linear(in_features=self.model.classifier[-1].in_features, out_features=self.n_classes, bias=True)(x))\n",
    "#         x = F.log_softmax(x, dim=1)\n",
    "        #self.model.classifier = nn.Sequential(*self.model.classifier, nn.Softmax())\n",
    "        if self.debug: print(f\"Num classes:{self.n_classes}\\nModel classifier\\n:{self.model_head}\")\n",
    "        return x\n",
    "\n",
    "    def add_classification_head(self):\n",
    "        #n_features = self.model_head.fc.in_features\n",
    "        classifier_layer = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.model_base.classifier[1].in_features, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512 , 256),\n",
    "            nn.Linear(256 , self.n_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "            )\n",
    "        return classifier_layer\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=1e-10)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def get_loss(self, y_hat, y):\n",
    "        #loss = nn.CrossEntropyLoss()   # does softmax for you (no need in classifcation)\n",
    "        #loss = nn.LogSoftmax()\n",
    "        #loss = F.nll_loss\n",
    "        if self.debug: print(y.size(), y.dtype, y_hat.size(), y_hat.dtype)\n",
    "        return F.cross_entropy(y_hat,  y)\n",
    "\n",
    "    def training_step(self, batch, batch_idx=None):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.get_loss(y_hat, y)\n",
    "        # training metrics\n",
    "        acc = self.accuracy(torch.argmax(y_hat, dim=1), y)\n",
    "        # optimize (done under the hoood)\n",
    "\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, logger=True)\n",
    "        return loss\n",
    "        #return self.get_loss(y, y_hat)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx=None):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        # compute metrics\n",
    "        val_loss =self.get_loss(y_hat, y)\n",
    "        acc = self.accuracy(torch.argmax(y_hat, dim=1), y)\n",
    "        auroc = self.AUROC(y_hat.cpu().detach(), y.cpu().detach())\n",
    "        #fpr, tpr, thresholds = self.ROC(y_hat, y)\n",
    "        #\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "        self.log('val_acc', acc, on_step=True, on_epoch=True, logger=True)\n",
    "        self.AUROC.update(y_hat.cpu().detach(), y.cpu().detach())\n",
    "        self.log(\"validation_auc\", self.AUROC, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        #self.log(\"val_auc\", valid_auc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "\n",
    "class HEEnsembleModel(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 ensembles_settings:dict={'efficientnetb7':3, 'resnext101':2}, \n",
    "                 pretrain:bool=True,\n",
    "                 n_classes:int=2,\n",
    "                 input_shape=(224,224),\n",
    "                 debug=False):\n",
    "        super(HEEnsembleModel, self).__init__()\n",
    "        self.debug = debug\n",
    "        models = []\n",
    "        self.n_models = 0\n",
    "        for name, number in ensembles_settings.items():\n",
    "            [models.append(\n",
    "                HEClassificationModel(model_name=name, \n",
    "                                      n_classes=2, \n",
    "                                      pretrain=pretrain,\n",
    "                                      custom_classification_head=False\n",
    "                                     )\n",
    "                         ) for i in range(number)\n",
    "            ]\n",
    "            self.n_models += number\n",
    "        self.ensemble_model = torch.nn.ModuleList(models)\n",
    "        self.classifier = torch.nn.Linear(self.n_models*n_classes, n_classes)\n",
    "        #self.save_hyperparameters() # Uncomment to show error\n",
    "        self.CEloss = nn.CrossEntropyLoss()\n",
    "        # metrics\n",
    "        self.accuracy = torchmetrics.Accuracy()\n",
    "        #self.ROC = torchmetrics.ROC(num_classes=n_classes)\n",
    "        self.AUROC = torchmetrics.AUROC(num_classes=n_classes, pos_label=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output=[]\n",
    "        for m in self.ensemble_model:\n",
    "            output.append(m(x))\n",
    "        combined = torch.concat(output,dim=1)\n",
    "        x = self.classifier(combined)\n",
    "        return x\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4, weight_decay=1e-10)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def get_loss(self, y_hat, y):\n",
    "        #loss = nn.CrossEntropyLoss()   # does softmax for you (no need in classifcation)\n",
    "        #loss = nn.LogSoftmax()\n",
    "        #loss = F.nll_loss\n",
    "        if self.debug: print(y.size(), y.dtype, y_hat.size(), y_hat.dtype)\n",
    "        return self.CEloss(y_hat,  y)\n",
    "\n",
    "    def training_step(self, batch, batch_idx=None):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.get_loss(y_hat, y)\n",
    "        # training metrics\n",
    "        acc = self.accuracy(torch.argmax(y_hat, dim=1), y)\n",
    "        # optimize (done under the hoood)\n",
    "\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, logger=True)\n",
    "        return loss\n",
    "        #return self.get_loss(y, y_hat)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx=None):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        # compute metrics\n",
    "        val_loss =self.get_loss(y_hat, y)\n",
    "        acc = self.accuracy(torch.argmax(y_hat, dim=1), y)\n",
    "        auroc = self.AUROC(y_hat.cpu().detach(), y.cpu().detach())\n",
    "        #fpr, tpr, thresholds = self.ROC(y_hat, y)\n",
    "        #\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "        self.log('val_acc', acc, on_step=True, on_epoch=True, logger=True)\n",
    "        self.AUROC.update(y_hat.cpu().detach(), y.cpu().detach())\n",
    "        self.log(\"validation_auc\", self.AUROC, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        #self.log(\"val_auc\", valid_auc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kl1KS1Qdq_05"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Kinjz3AgaGjB"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from pytorch_lightning.callbacks import EarlyStopping, GradientAccumulationScheduler\n",
    "import pytorch_lightning as pl\n",
    "# logger\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "#\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Gk2iGQLALW7W"
   },
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "    '''\n",
    "        Try resetting model weights to avoid\n",
    "        weight leakage.\n",
    "    '''\n",
    "    for layer in m.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            print(f'Reset trainable parameters of layer = {layer}')\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "1aoYeC2oNT2A",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MisconfigurationException",
     "evalue": "`Trainer(strategy='ddp_spawn')` is not compatible with an interactive environment. Run your code as a script, or choose one of the compatible strategies: Trainer(strategy=None|dp|tpu_spawn|ddp_fork). In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [39], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# DEFAULT (ie: no accumulated grads)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m cbs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      3\u001b[0m     pl\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, dirpath\u001b[38;5;241m=\u001b[39mPATH_ARGS\u001b[38;5;241m.\u001b[39mmodel_path,\n\u001b[0;32m      4\u001b[0m                                  filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels-\u001b[39m\u001b[38;5;132;01m{epoch:02d}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{val_loss:.2f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, save_top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m#PRMetrics(),\u001b[39;00m\n\u001b[0;32m      8\u001b[0m ]\n\u001b[1;32m----> 9\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mWandbLogger\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAD-ensemble(draft)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mentity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m3m-m\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRAIN_ARGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcbs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mddp_spawn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#trainer = Trainer(accelerator=\"gpu\", devices=2, num_nodes=4)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m HEEnsembleModel(ensembles_settings\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mefficientnetb7\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     18\u001b[0m                                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmobilenetv3\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     19\u001b[0m                                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresnext101\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m2\u001b[39m},\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m                         n_classes\u001b[38;5;241m=\u001b[39mMODEL_ARGS\u001b[38;5;241m.\u001b[39mn_classes,\n\u001b[0;32m     23\u001b[0m                         debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ensemble_vision\\lib\\site-packages\\pytorch_lightning\\utilities\\argparse.py:345\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    342\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(env_variables\u001b[38;5;241m.\u001b[39mitems()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# all args were already moved to kwargs\u001b[39;00m\n\u001b[1;32m--> 345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ensemble_vision\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:433\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, logger, enable_checkpointing, callbacks, default_root_dir, gradient_clip_val, gradient_clip_algorithm, num_nodes, num_processes, devices, gpus, auto_select_gpus, tpu_cores, ipus, enable_progress_bar, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, val_check_interval, log_every_n_steps, accelerator, strategy, sync_batchnorm, precision, enable_model_summary, weights_save_path, num_sanity_val_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_n_epochs, auto_lr_find, replace_sampler_ddp, detect_anomaly, auto_scale_batch_size, plugins, amp_backend, amp_level, move_metrics_to_cpu, multiple_trainloader_mode)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# init connectors\u001b[39;00m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector \u001b[38;5;241m=\u001b[39m DataConnector(\u001b[38;5;28mself\u001b[39m, multiple_trainloader_mode)\n\u001b[1;32m--> 433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerator_connector \u001b[38;5;241m=\u001b[39m \u001b[43mAcceleratorConnector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_processes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtpu_cores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtpu_cores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mipus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mipus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43msync_batchnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msync_batchnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbenchmark\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbenchmark\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreplace_sampler_ddp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplace_sampler_ddp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_select_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_select_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamp_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamp_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamp_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamp_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplugins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplugins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger_connector \u001b[38;5;241m=\u001b[39m LoggerConnector(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_connector \u001b[38;5;241m=\u001b[39m CallbackConnector(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ensemble_vision\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:230\u001b[0m, in \u001b[0;36mAcceleratorConnector.__init__\u001b[1;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, amp_type, amp_level, sync_batchnorm, benchmark, replace_sampler_ddp, deterministic, auto_select_gpus, num_processes, tpu_cores, ipus, gpus)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_and_init_precision()\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# 6. Instantiate Strategy - Part 2\u001b[39;00m\n\u001b[1;32m--> 230\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_init_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ensemble_vision\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:817\u001b[0m, in \u001b[0;36mAcceleratorConnector._lazy_init_strategy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IS_INTERACTIVE\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _IS_INTERACTIVE \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mis_interactive_compatible:\n\u001b[1;32m--> 817\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\n\u001b[0;32m    818\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Trainer(strategy=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mstrategy_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m)` is not compatible with an interactive\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    819\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m environment. Run your code as a script, or choose one of the compatible strategies:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Trainer(strategy=None|\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(_StrategyType\u001b[38;5;241m.\u001b[39minteractive_compatible_types())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m In case you are spawning processes yourself, make sure to include the Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m creation inside the worker function.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    823\u001b[0m     )\n\u001b[0;32m    825\u001b[0m \u001b[38;5;66;03m# TODO: should be moved to _check_strategy_and_fallback().\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;66;03m# Current test check precision first, so keep this check here to meet error order\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator, TPUAccelerator) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy, (SingleTPUStrategy, TPUSpawnStrategy)\n\u001b[0;32m    829\u001b[0m ):\n",
      "\u001b[1;31mMisconfigurationException\u001b[0m: `Trainer(strategy='ddp_spawn')` is not compatible with an interactive environment. Run your code as a script, or choose one of the compatible strategies: Trainer(strategy=None|dp|tpu_spawn|ddp_fork). In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: While tearing down the service manager. The following error has occured: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    }
   ],
   "source": [
    "# DEFAULT (ie: no accumulated grads)\n",
    "cbs = [\n",
    "    pl.callbacks.ModelCheckpoint(monitor='val_loss', dirpath=PATH_ARGS.model_path,\n",
    "                                 filename='models-{epoch:02d}-{val_loss:.2f}', save_top_k=2, mode='min'),\n",
    "    EarlyStopping(monitor=\"val_loss\", min_delta=1e-7, patience=8, mode=\"min\"),\n",
    "    GradientAccumulationScheduler(scheduling={0: 8, 4: 4, 8: 1}),\n",
    "    #PRMetrics(),\n",
    "]\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=2,\n",
    "    logger=WandbLogger(project='AD-ensemble(draft)',  entity=\"3m-m\", job_type='train'),\n",
    "    max_epochs=TRAIN_ARGS.epochs, callbacks=cbs,\n",
    "    strategy='ddp_spawn'\n",
    ")\n",
    "#trainer = Trainer(accelerator=\"gpu\", devices=2, num_nodes=4)\n",
    "model = HEEnsembleModel(ensembles_settings={'efficientnetb7':1,\n",
    "                                            'mobilenetv3':2,\n",
    "                                            'resnext101':2},\n",
    "                        pretrain=False,\n",
    "                        input_shape=(224,224),\n",
    "                        n_classes=MODEL_ARGS.n_classes,\n",
    "                        debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dBQBmVGE3u_M"
   },
   "outputs": [],
   "source": [
    "# train\n",
    "datamodule = HEDataModule(batch_size=TRAIN_ARGS.epochs, dataindex_path=PATH_ARGS.dataindex_path, debug=False)\n",
    "datamodule.setup()\n",
    "trainer.fit(model=model, datamodule=datamodule) \n",
    "print(\"Done\")\n",
    "# save with parameters\n",
    "#torch.save([model.kwargs, model.state_dict()], path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v65ctfW7HABS"
   },
   "source": [
    "### Prediction/submission"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "uUsLsFHLv8b8"
   },
   "source": [
    "test_loader = DataLoader(HEdatasets['test'], shuffle=True, batch_size=TRAIN_args.test_batch_size)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "dca68bea1ee5b3be888f6b0e1f9475265928937e00d73db3ed64c34751d2276f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
